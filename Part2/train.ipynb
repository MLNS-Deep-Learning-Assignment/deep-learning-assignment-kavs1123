{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data0 = np.load('data0.npy')\n",
    "train_lab0 = np.load('lab0.npy')\n",
    "\n",
    "train_data1 = np.load('data1.npy')\n",
    "train_lab1 = np.load('lab1.npy')\n",
    "\n",
    "train_data2 = np.load('data2.npy')\n",
    "train_lab2 = np.load('lab2.npy')\n",
    "\n",
    "final_train = np.concatenate((train_data0 , train_data1 , train_data2) , axis=0)\n",
    "final_labels = np.concatenate((train_lab0,train_lab1,train_lab2), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(final_train, final_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = torch.FloatTensor(images.reshape(-1, 1, 40, 168)) / 255.0\n",
    "        self.labels = torch.FloatTensor(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(X_train, y_train)\n",
    "val_dataset = MyDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedDigitSumCNN(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.5):\n",
    "        super(AdvancedDigitSumCNN, self).__init__()\n",
    "        \n",
    "       \n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        \n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv2d(128, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(128, 256)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        \n",
    "       \n",
    "        attention_weights = self.attention(x)\n",
    "        x = x * attention_weights\n",
    "        \n",
    "        \n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "## Added focal l1 loss cause read that it might be better for such a task.\n",
    "class FocalL1Loss(nn.Module):\n",
    "    def __init__(self, alpha=2.0, beta=0.25, epsilon=1e-6):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        l1_loss = torch.abs(pred - target)\n",
    "        l1_loss = torch.clamp(l1_loss, min=self.epsilon)  \n",
    "        focal_factor = torch.pow(l1_loss, self.alpha)\n",
    "        loss = focal_factor * l1_loss\n",
    "        return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_adv(model, train_loader, val_loader, criterion, optimizer, device, epochs=10):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_path = \"advmodel.pth\"\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs.squeeze(), labels)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"Best model saved with Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    print(\"Training complete. Best model saved as advmodel.pth.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "advmodel = AdvancedDigitSumCNN()\n",
    "advcriterion = FocalL1Loss()\n",
    "optimizer = optim.Adam(advmodel.parameters(), lr=0.001)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 177.1652, Val Loss: 146.0568\n",
      "Best model saved with Val Loss: 146.0568\n",
      "Epoch 2/50, Train Loss: 123.5872, Val Loss: 46.3448\n",
      "Best model saved with Val Loss: 46.3448\n",
      "Epoch 3/50, Train Loss: 100.7178, Val Loss: 66.7292\n",
      "Epoch 4/50, Train Loss: 90.2490, Val Loss: 22.0596\n",
      "Best model saved with Val Loss: 22.0596\n",
      "Epoch 5/50, Train Loss: 85.5029, Val Loss: 23.4490\n",
      "Epoch 6/50, Train Loss: 76.7190, Val Loss: 30.3449\n",
      "Epoch 7/50, Train Loss: 70.8224, Val Loss: 51.3272\n",
      "Epoch 8/50, Train Loss: 63.1695, Val Loss: 16.7730\n",
      "Best model saved with Val Loss: 16.7730\n",
      "Epoch 9/50, Train Loss: 59.7111, Val Loss: 46.0979\n",
      "Epoch 10/50, Train Loss: 55.2708, Val Loss: 31.6795\n",
      "Epoch 11/50, Train Loss: 49.8542, Val Loss: 20.4186\n",
      "Epoch 12/50, Train Loss: 45.6918, Val Loss: 12.1415\n",
      "Best model saved with Val Loss: 12.1415\n",
      "Epoch 13/50, Train Loss: 43.2284, Val Loss: 12.1626\n",
      "Epoch 14/50, Train Loss: 41.1865, Val Loss: 10.0756\n",
      "Best model saved with Val Loss: 10.0756\n",
      "Epoch 15/50, Train Loss: 38.2774, Val Loss: 19.4200\n",
      "Epoch 16/50, Train Loss: 36.3522, Val Loss: 10.1427\n",
      "Epoch 17/50, Train Loss: 33.1167, Val Loss: 10.3562\n",
      "Epoch 18/50, Train Loss: 33.2183, Val Loss: 12.8516\n",
      "Epoch 19/50, Train Loss: 31.6574, Val Loss: 17.4388\n",
      "Epoch 20/50, Train Loss: 29.0583, Val Loss: 29.8403\n",
      "Epoch 21/50, Train Loss: 30.5098, Val Loss: 11.1493\n",
      "Epoch 22/50, Train Loss: 27.6349, Val Loss: 12.4401\n",
      "Epoch 23/50, Train Loss: 26.0216, Val Loss: 12.0377\n",
      "Epoch 24/50, Train Loss: 24.8432, Val Loss: 14.9721\n",
      "Epoch 25/50, Train Loss: 24.9364, Val Loss: 11.4899\n",
      "Epoch 26/50, Train Loss: 24.0115, Val Loss: 10.9371\n",
      "Epoch 27/50, Train Loss: 21.8948, Val Loss: 7.4711\n",
      "Best model saved with Val Loss: 7.4711\n",
      "Epoch 28/50, Train Loss: 21.8268, Val Loss: 7.4636\n",
      "Best model saved with Val Loss: 7.4636\n",
      "Epoch 29/50, Train Loss: 21.5482, Val Loss: 9.6520\n",
      "Epoch 30/50, Train Loss: 20.3441, Val Loss: 8.9289\n",
      "Epoch 31/50, Train Loss: 19.7430, Val Loss: 8.6752\n",
      "Epoch 32/50, Train Loss: 18.7614, Val Loss: 7.9493\n",
      "Epoch 33/50, Train Loss: 18.9037, Val Loss: 8.9352\n",
      "Epoch 34/50, Train Loss: 18.2867, Val Loss: 9.6730\n",
      "Epoch 35/50, Train Loss: 17.7694, Val Loss: 7.3309\n",
      "Best model saved with Val Loss: 7.3309\n",
      "Epoch 36/50, Train Loss: 16.9863, Val Loss: 9.8771\n",
      "Epoch 37/50, Train Loss: 15.6869, Val Loss: 7.0164\n",
      "Best model saved with Val Loss: 7.0164\n",
      "Epoch 38/50, Train Loss: 15.7110, Val Loss: 13.4026\n",
      "Epoch 39/50, Train Loss: 16.4418, Val Loss: 10.1422\n",
      "Epoch 40/50, Train Loss: 14.3321, Val Loss: 7.6555\n",
      "Epoch 41/50, Train Loss: 14.6410, Val Loss: 11.8238\n",
      "Epoch 42/50, Train Loss: 13.6075, Val Loss: 6.7100\n",
      "Best model saved with Val Loss: 6.7100\n",
      "Epoch 43/50, Train Loss: 12.9401, Val Loss: 7.1981\n",
      "Epoch 44/50, Train Loss: 12.8579, Val Loss: 7.4562\n",
      "Epoch 45/50, Train Loss: 13.4574, Val Loss: 11.4925\n",
      "Epoch 46/50, Train Loss: 12.4236, Val Loss: 7.4756\n",
      "Epoch 47/50, Train Loss: 11.9361, Val Loss: 7.1315\n",
      "Epoch 48/50, Train Loss: 11.2934, Val Loss: 11.3658\n",
      "Epoch 49/50, Train Loss: 11.0489, Val Loss: 6.8924\n",
      "Epoch 50/50, Train Loss: 11.0867, Val Loss: 7.7011\n",
      "Training complete. Best model saved as advmodel.pth.\n"
     ]
    }
   ],
   "source": [
    "train_model_adv(advmodel, train_loader, val_loader, advcriterion, optimizer, device , epochs=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 15.00, Actual: 15.00\n",
      "Prediction: 17.00, Actual: 18.00\n",
      "Prediction: 18.00, Actual: 19.00\n",
      "Prediction: 26.00, Actual: 26.00\n",
      "Prediction: 24.00, Actual: 25.00\n",
      "Prediction: 13.00, Actual: 14.00\n",
      "Prediction: 10.00, Actual: 10.00\n",
      "Prediction: 24.00, Actual: 23.00\n",
      "Prediction: 17.00, Actual: 19.00\n",
      "Prediction: 18.00, Actual: 20.00\n"
     ]
    }
   ],
   "source": [
    "advmodel.eval()\n",
    "example_images, actual_labels = next(iter(val_loader))  \n",
    "example_images = example_images.to(device) \n",
    "\n",
    "\n",
    "predictions = advmodel(example_images).detach().cpu().numpy()\n",
    "rounded_pred = predictions.round()\n",
    "\n",
    "\n",
    "for i in range(10): \n",
    "    print(f\"Prediction: {rounded_pred[i][0]:.2f}, Actual: {actual_labels[i].item():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class ResNetSumPredictor(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(ResNetSumPredictor, self).__init__()\n",
    "\n",
    "        self.resnet = models.resnet50(pretrained=pretrained)\n",
    "\n",
    "\n",
    "        self.resnet.conv1 = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=64,\n",
    "            kernel_size=7,\n",
    "            stride=2,\n",
    "            padding=3,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "        if pretrained:\n",
    "            state_dict = models.resnet50(pretrained=True).state_dict()\n",
    "\n",
    "            state_dict['conv1.weight'] = state_dict['conv1.weight'].sum(dim=1, keepdim=True)\n",
    "            self.resnet.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "\n",
    "\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(num_features, 1)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "\n",
    "resmodel = ResNetSumPredictor(pretrained=True)\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(resmodel.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_res(model, train_loader, val_loader, criterion, optimizer, device , epochs=10):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_path = \"resmodel.pth\"\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs.squeeze(), labels)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"Best model saved with Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    print(\"Training complete. Best model saved as resmodel.pth.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 7.1914, Val Loss: 9.4816\n",
      "Best model saved with Val Loss: 9.4816\n",
      "Epoch 2/50, Train Loss: 2.5557, Val Loss: 3.0220\n",
      "Best model saved with Val Loss: 3.0220\n",
      "Epoch 3/50, Train Loss: 1.9616, Val Loss: 1.1972\n",
      "Best model saved with Val Loss: 1.1972\n",
      "Epoch 4/50, Train Loss: 1.4332, Val Loss: 2.0275\n",
      "Epoch 5/50, Train Loss: 1.1669, Val Loss: 1.4186\n",
      "Epoch 6/50, Train Loss: 1.1432, Val Loss: 1.3201\n",
      "Epoch 7/50, Train Loss: 0.8383, Val Loss: 0.7575\n",
      "Best model saved with Val Loss: 0.7575\n",
      "Epoch 8/50, Train Loss: 0.8641, Val Loss: 0.8375\n",
      "Epoch 9/50, Train Loss: 0.6973, Val Loss: 0.8223\n",
      "Epoch 10/50, Train Loss: 0.6886, Val Loss: 0.7765\n",
      "Epoch 11/50, Train Loss: 0.5284, Val Loss: 0.8024\n",
      "Epoch 12/50, Train Loss: 0.5540, Val Loss: 0.6732\n",
      "Best model saved with Val Loss: 0.6732\n",
      "Epoch 13/50, Train Loss: 0.5098, Val Loss: 0.8748\n",
      "Epoch 14/50, Train Loss: 0.4418, Val Loss: 0.6863\n",
      "Epoch 15/50, Train Loss: 0.5415, Val Loss: 0.5574\n",
      "Best model saved with Val Loss: 0.5574\n",
      "Epoch 16/50, Train Loss: 0.3988, Val Loss: 0.4902\n",
      "Best model saved with Val Loss: 0.4902\n",
      "Epoch 17/50, Train Loss: 0.3103, Val Loss: 0.8385\n",
      "Epoch 18/50, Train Loss: 0.4519, Val Loss: 0.7076\n",
      "Epoch 19/50, Train Loss: 0.2672, Val Loss: 0.9143\n",
      "Epoch 20/50, Train Loss: 0.2538, Val Loss: 0.6551\n",
      "Epoch 21/50, Train Loss: 0.4310, Val Loss: 0.4731\n",
      "Best model saved with Val Loss: 0.4731\n",
      "Epoch 22/50, Train Loss: 0.3573, Val Loss: 0.6439\n",
      "Epoch 23/50, Train Loss: 0.2990, Val Loss: 0.5579\n",
      "Epoch 24/50, Train Loss: 0.1924, Val Loss: 0.5534\n",
      "Epoch 25/50, Train Loss: 0.2610, Val Loss: 0.8718\n",
      "Epoch 26/50, Train Loss: 0.2760, Val Loss: 0.5447\n",
      "Epoch 27/50, Train Loss: 0.1776, Val Loss: 0.5344\n",
      "Epoch 28/50, Train Loss: 0.1884, Val Loss: 0.4605\n",
      "Best model saved with Val Loss: 0.4605\n",
      "Epoch 29/50, Train Loss: 0.3264, Val Loss: 0.5575\n",
      "Epoch 30/50, Train Loss: 0.1982, Val Loss: 0.4450\n",
      "Best model saved with Val Loss: 0.4450\n",
      "Epoch 31/50, Train Loss: 0.1657, Val Loss: 0.4360\n",
      "Best model saved with Val Loss: 0.4360\n",
      "Epoch 32/50, Train Loss: 0.1544, Val Loss: 0.4432\n",
      "Epoch 33/50, Train Loss: 0.1853, Val Loss: 0.5901\n",
      "Epoch 34/50, Train Loss: 0.2603, Val Loss: 0.6110\n",
      "Epoch 35/50, Train Loss: 0.1109, Val Loss: 0.5579\n",
      "Epoch 36/50, Train Loss: 0.1664, Val Loss: 0.5883\n",
      "Epoch 37/50, Train Loss: 0.1999, Val Loss: 1.0754\n",
      "Epoch 38/50, Train Loss: 0.1264, Val Loss: 0.3678\n",
      "Best model saved with Val Loss: 0.3678\n",
      "Epoch 39/50, Train Loss: 0.1201, Val Loss: 0.4322\n",
      "Epoch 40/50, Train Loss: 0.1407, Val Loss: 0.4197\n",
      "Epoch 41/50, Train Loss: 0.1412, Val Loss: 0.5100\n",
      "Epoch 42/50, Train Loss: 0.1934, Val Loss: 0.4689\n",
      "Epoch 43/50, Train Loss: 0.1718, Val Loss: 0.4873\n",
      "Epoch 44/50, Train Loss: 0.0834, Val Loss: 0.2638\n",
      "Best model saved with Val Loss: 0.2638\n",
      "Epoch 45/50, Train Loss: 0.1047, Val Loss: 0.4249\n",
      "Epoch 46/50, Train Loss: 0.2096, Val Loss: 0.3732\n",
      "Epoch 47/50, Train Loss: 0.1689, Val Loss: 0.4856\n",
      "Epoch 48/50, Train Loss: 0.0960, Val Loss: 0.6002\n",
      "Epoch 49/50, Train Loss: 0.1373, Val Loss: 0.4973\n",
      "Epoch 50/50, Train Loss: 0.1424, Val Loss: 0.4924\n",
      "Training complete. Best model saved as resmodel.pth.\n"
     ]
    }
   ],
   "source": [
    "train_model_res(resmodel , train_loader , val_loader, criterion,optimizer,device,epochs=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
